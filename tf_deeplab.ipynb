{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_deeplab.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1NcrtNuLVC_grJwTC1VJCQVkw2VnWdZBo","authorship_tag":"ABX9TyNaxWX+Ucb9aLHH2+mWBwMV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Npl64fhLoz_k"},"source":["!pip install tensorflow==1.15"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"flpkxRmLof-z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620626262287,"user_tz":-540,"elapsed":6025,"user":{"displayName":"임수빈","photoUrl":"https://lh4.googleusercontent.com/-shQjEu-1d-U/AAAAAAAAAAI/AAAAAAAAALQ/0wWCQNge2WI/s64/photo.jpg","userId":"18239898010736387958"}},"outputId":"49ac66b7-7f75-4b82-965a-352fae72d0b9"},"source":["import os\n","from io import BytesIO\n","import tarfile\n","import tempfile\n","from six.moves import urllib\n","\n","from matplotlib import gridspec\n","from matplotlib import pyplot as plt\n","import numpy as np\n","from PIL import Image\n","\n","%tensorflow_version 1.x\n","import tensorflow as tf"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRUXk67zpDGM","executionInfo":{"status":"ok","timestamp":1620629213249,"user_tz":-540,"elapsed":737,"user":{"displayName":"임수빈","photoUrl":"https://lh4.googleusercontent.com/-shQjEu-1d-U/AAAAAAAAAAI/AAAAAAAAALQ/0wWCQNge2WI/s64/photo.jpg","userId":"18239898010736387958"}}},"source":["class DeepLabModel(object):\n","  \"\"\"Class to load deeplab model and run inference.\"\"\"\n","\n","  INPUT_TENSOR_NAME = 'ImageTensor:0'\n","  OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n","  INPUT_SIZE = 513\n","  FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n","\n","  def __init__(self, tarball_path):\n","    \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n","    self.graph = tf.Graph()\n","\n","    graph_def = None\n","    # Extract frozen graph from tar archive.\n","    tar_file = tarfile.open(tarball_path)\n","    for tar_info in tar_file.getmembers():\n","      if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n","        file_handle = tar_file.extractfile(tar_info)\n","        graph_def = tf.GraphDef.FromString(file_handle.read())\n","        break\n","\n","    tar_file.close()\n","\n","    if graph_def is None:\n","      raise RuntimeError('Cannot find inference graph in tar archive.')\n","\n","    with self.graph.as_default():\n","      tf.import_graph_def(graph_def, name='')\n","\n","    self.sess = tf.Session(graph=self.graph)\n","\n","  def run(self, image):\n","    \"\"\"Runs inference on a single image.\n","\n","    Args:\n","      image: A PIL.Image object, raw input image.\n","\n","    Returns:\n","      resized_image: RGB image resized from original input image.\n","      seg_map: Segmentation map of `resized_image`.\n","    \"\"\"\n","    width, height = image.size\n","    resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n","    target_size = (int(resize_ratio * width), int(resize_ratio * height))\n","    resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n","    batch_seg_map = self.sess.run(\n","        self.OUTPUT_TENSOR_NAME,\n","        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n","    seg_map = batch_seg_map[0]\n","    return resized_image, seg_map\n","\n","\n","def create_pascal_label_colormap():\n","  \"\"\"Creates a label colormap used in PASCAL VOC segmentation benchmark.\n","\n","  Returns:\n","    A Colormap for visualizing segmentation results.\n","  \"\"\"\n","  colormap = np.zeros((256, 3), dtype=int)\n","  ind = np.arange(256, dtype=int)\n","\n","  for shift in reversed(range(8)):\n","    for channel in range(3):\n","      colormap[:, channel] |= ((ind >> channel) & 1) << shift\n","    ind >>= 3\n","\n","  return colormap\n","\n","\n","def label_to_color_image(label):\n","  \"\"\"Adds color defined by the dataset colormap to the label.\n","\n","  Args:\n","    label: A 2D array with integer type, storing the segmentation label.\n","\n","  Returns:\n","    result: A 2D array with floating type. The element of the array\n","      is the color indexed by the corresponding element in the input label\n","      to the PASCAL color map.\n","\n","  Raises:\n","    ValueError: If label is not of rank 2 or its value is larger than color\n","      map maximum entry.\n","  \"\"\"\n","  if label.ndim != 2:\n","    raise ValueError('Expect 2-D input label')\n","\n","  colormap = create_pascal_label_colormap()\n","\n","  if np.max(label) >= len(colormap):\n","    raise ValueError('label value too large.')\n","\n","  return colormap[label]\n","\n","def save_output(image, seg_map, filename):\n","  \"\"\" 폴더에 output 저장 \"\"\"\n","  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n","  plt.imshow(seg_image)\n","  plt.axis('off')\n","  plt.savefig('/content/drive/MyDrive/dataset/output_labelname/%s' %filename, bbox_inches='tight', transparent=True)\n","\n","\n","def vis_segmentation(image, seg_map):\n","  \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\n","  plt.figure(figsize=(15, 5))\n","  grid_spec = gridspec.GridSpec(1, 4, width_ratios=[6, 6, 6, 1])\n","\n","  plt.subplot(grid_spec[0])\n","  plt.imshow(image)\n","  plt.axis('off')\n","  plt.title('input image')\n","\n","  plt.subplot(grid_spec[1])\n","  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n","  plt.imshow(seg_image)\n","  plt.axis('off')\n","  plt.title('segmentation map')\n","\n","\n","  plt.subplot(grid_spec[2])\n","  plt.imshow(image)\n","  plt.imshow(seg_image, alpha=0.7)\n","  plt.axis('off')\n","  plt.title('segmentation overlay')\n","\n","  unique_labels = np.unique(seg_map)\n","  ax = plt.subplot(grid_spec[3])\n","  plt.imshow(\n","      FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n","  ax.yaxis.tick_right()\n","  plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n","  plt.xticks([], [])\n","  ax.tick_params(width=0.0)\n","  plt.grid('off')\n","  plt.show()\n","\n","\n","#LABEL_NAMES = np.asarray(['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus','car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike','person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'])\n","\n","LABEL_NAMES = np.asarray(['Bicyclist', 'Pedestrain', 'Car', 'Fence', 'SignSymbol', 'Tree', 'Pavernent', 'Road', 'Pole', 'Building', 'Sky'])\n","\n","FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n","FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zZCoHxW0pHmM","executionInfo":{"status":"ok","timestamp":1620626281965,"user_tz":-540,"elapsed":14046,"user":{"displayName":"임수빈","photoUrl":"https://lh4.googleusercontent.com/-shQjEu-1d-U/AAAAAAAAAAI/AAAAAAAAALQ/0wWCQNge2WI/s64/photo.jpg","userId":"18239898010736387958"}},"outputId":"3db9be30-1f7d-476e-e9a9-9f54d54459e9"},"source":["MODEL_NAME = 'xception_coco_voctrainaug'  # @param ['mobilenetv2_coco_voctrainaug', 'mobilenetv2_coco_voctrainval', 'xception_coco_voctrainaug', 'xception_coco_voctrainval']\n","\n","_DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n","_MODEL_URLS = {\n","    'mobilenetv2_coco_voctrainaug':\n","        'deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz',\n","    'mobilenetv2_coco_voctrainval':\n","        'deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz',\n","    'xception_coco_voctrainaug':\n","        'deeplabv3_pascal_train_aug_2018_01_04.tar.gz',\n","    'xception_coco_voctrainval':\n","        'deeplabv3_pascal_trainval_2018_01_04.tar.gz',\n","}\n","_TARBALL_NAME = 'deeplab_model.tar.gz'\n","\n","model_dir = tempfile.mkdtemp()\n","tf.gfile.MakeDirs(model_dir)\n","\n","download_path = os.path.join(model_dir, _TARBALL_NAME)\n","print('downloading model, this might take a while...')\n","urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + _MODEL_URLS[MODEL_NAME],\n","                   download_path)\n","print('download completed! loading DeepLab model...')\n","\n","MODEL = DeepLabModel(download_path)\n","print('model loaded successfully!')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["downloading model, this might take a while...\n","download completed! loading DeepLab model...\n","model loaded successfully!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yV1clNT1pJvc"},"source":["SAMPLE_IMAGE = 'image3'  # @param ['image1', 'image2', 'image3']\n","IMAGE_URL = ''  #@param {type:\"string\"}\n","\n","_SAMPLE_URL = ('https://github.com/tensorflow/models/blob/master/research/'\n","               'deeplab/g3doc/img/%s.jpg?raw=true')\n","\n","\n","def run_visualization(url):\n","  \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n","  try:\n","    f = urllib.request.urlopen(url)\n","    jpeg_str = f.read()\n","    original_im = Image.open(BytesIO(jpeg_str))\n","  except IOError:\n","    print('Cannot retrieve image. Please check url: ' + url)\n","    return\n","\n","  print('running deeplab on image %s...' % url)\n","  resized_im, seg_map = MODEL.run(original_im)\n","\n","  vis_segmentation(resized_im, seg_map)\n","\n","\n","image_url = IMAGE_URL or _SAMPLE_URL % SAMPLE_IMAGE\n","run_visualization(image_url)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9eFVnBz2zXb9"},"source":["def run_visualization():\n","  \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n","\n","  try:\n","    dir = '/content/drive/MyDrive/dataset/Original_data' ##경로 수정!!!!!!!!!!\n","    for filename in os.listdir(dir):\n","      path = '/content/drive/MyDrive/dataset/Original_data/%s' %filename ##경로 수정!!!!!!!!!!\n","      with open(path, 'rb') as f:\n","        jpeg_str = f.read()\n","        original_im = Image.open(BytesIO(jpeg_str))\n","\n","        print('running deeplab on image %s...' %filename)\n","        resized_im, seg_map = MODEL.run(original_im)\n","\n","        save_output(resized_im, seg_map, filename)\n","  \n","  except IOError:\n","    print('Cannot retrieve image. Please check url')\n","    return\n","\n","run_visualization()"],"execution_count":null,"outputs":[]}]}