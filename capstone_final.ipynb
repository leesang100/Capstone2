{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capstone_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5xcA5AuDP7J"
      },
      "source": [
        "데이터 불러오기\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPO3hh80TmbG"
      },
      "source": [
        "colormap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IKUPANxDM2D"
      },
      "source": [
        "import pandas as pd\n",
        "classes = pd.read_csv(data_path+'class_dict.csv', index_col =0)\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41bj3Q4uDaat"
      },
      "source": [
        "n_classes = len(classes)\n",
        "n_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0nplon_TZTn"
      },
      "source": [
        "데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AgyCQFyGNDs"
      },
      "source": [
        "# Data generator\n",
        "#https://keras.io/preprocessing/image/\n",
        "# Data generator\n",
        "#batch_sz = 4\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# we create two instances with the same arguments\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest',\n",
        "                    rescale=1./255)\n",
        "\n",
        "mask_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen  = ImageDataGenerator(**mask_gen_args) \n",
        "\n",
        "# Provide the same seed and keyword arguments to the fit and flow methods\n",
        "seed = 1\n",
        "#image_datagen.fit(images, augment=True, seed=seed)\n",
        "#mask_datagen.fit(masks, augment=True, seed=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMgQVUf4SWxn"
      },
      "source": [
        "data_path  6개 만들어야할 것 같은데..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVTUkDzHSWaf"
      },
      "source": [
        "data_path="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iBQLCkPTv7w"
      },
      "source": [
        "generator 단위로 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrcZpDb5Lf9r"
      },
      "source": [
        "###train\n",
        "image_generator = image_datagenflow_from_directory.(\n",
        "    data_path,\n",
        "    class_mode=None,\n",
        "    classes=['Original_Train'],\n",
        "    seed=seed,\n",
        "    batch_size=batch_sz,\n",
        "    target_size=(256,256))\n",
        "\n",
        "mask_generator = mask_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    classes=['Mask_Train'],\n",
        "    class_mode=None,\n",
        "    seed=seed,\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_sz,\n",
        "    target_size=(256,256))\n",
        "\n",
        "# combine generators into one which yields image and masks\n",
        "train_generator = zip(image_generator, mask_generator)\n",
        "\n",
        "###validation\n",
        "val_image_generator = image_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    class_mode=None,\n",
        "    classes=['Original_val'],\n",
        "    seed=seed,\n",
        "    batch_size=batch_sz,\n",
        "    target_size=(256,256))\n",
        "\n",
        "val_mask_generator = mask_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    classes=['Mask_val'],\n",
        "    class_mode=None,\n",
        "    seed=seed,\n",
        "    batch_size=batch_sz,\n",
        "    color_mode='rgb',\n",
        "    target_size=(256,256))\n",
        "\n",
        "# combine generators into one which yields image and masks\n",
        "val_generator = zip(val_image_generator, val_mask_generator)\n",
        "\n",
        "###test\n",
        "test_image_generator=image_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    class_mode=None,\n",
        "    classes=['Original_Test'],\n",
        "    seed=seed,\n",
        "    batch_size=batch_sz,\n",
        "    color_mode='rgb',\n",
        "    target_size=(256,256))\n",
        "\n",
        "test_mask_generator=image_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    class_mode=None,\n",
        "    classes=['Mask_Test'],\n",
        "    seed=seed,\n",
        "    batch_size=batch_sz,\n",
        "    color_mode='rgb',\n",
        "    target_size=(256,256))\n",
        "\n",
        "test_generator=zip(test_image_generator,test_mask_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzoJTBT4D44W"
      },
      "source": [
        "UNET 모델 정의\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETS8ICJAD6xn"
      },
      "source": [
        "import numpy as np \n",
        "import os\n",
        "#import skimage.io as io\n",
        "#import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "\n",
        "\n",
        "def unet(n_classes, pretrained_weights = None,input_size = (256,256,3), flat=False, ohe=True):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    #conv10 = Conv2D(n_classes, (1,1), activation = 'softmax')(conv9)\n",
        "    conv10 = Conv2D(n_classes, (1,1), padding='same')(conv9)\n",
        "    if flat:\n",
        "        output_layer = Reshape((256*256,n_classes))(conv10)\n",
        "    else:\n",
        "        output_layer = conv10\n",
        "    output_layer = Activation('softmax')(output_layer)\n",
        "     \n",
        "\n",
        "    model = Model( inputs,output_layer)\n",
        "\n",
        "    if ohe:\n",
        "         model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.MeanIoU(num_classes=32)])\n",
        "    else:\n",
        "        model.compile(optimizer = Adam(lr = 1e-4), loss = 'sparse_categorical_crossentropy', metrics = [tf.keras.metrics.MeanIoU(num_classes=32)])\n",
        "    \n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4YtljOjD9e-"
      },
      "source": [
        "model = unet(n_classes)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJYO5oh3GJ19"
      },
      "source": [
        "Data generator 정의\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Nj_aoHDpnF"
      },
      "source": [
        "def adjust_mask(mask, flat=False):\n",
        "    \n",
        "    semantic_map = []\n",
        "    for colour in list(cls2rgb.values()):        \n",
        "        equality = np.equal(mask, colour)# 256x256x3 with True or False\n",
        "        class_map = np.all(equality, axis = -1)# 256x256 If all True, then True, else False\n",
        "        semantic_map.append(class_map)# List of 256x256 arrays, map of True for a given found color at the pixel, and False otherwise.\n",
        "    semantic_map = np.stack(semantic_map, axis=-1)# 256x256x32 True only at the found color, and all False otherwise.\n",
        "    if flat:\n",
        "        semantic_map = np.reshape(semantic_map, (-1,256*256))\n",
        "\n",
        "    return np.float32(semantic_map)# convert to numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyyubBaCDxDm"
      },
      "source": [
        "#new_mask = adjust_mask(mask)\n",
        "#new_mask.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUUuJV6oS4Su"
      },
      "source": [
        "def train_generator_fn():\n",
        "    for (img,mask) in train_generator:\n",
        "        new_mask = adjust_mask(mask)\n",
        "        yield (img,new_mask)\n",
        "\n",
        "def val_generator_fn():\n",
        "    for (img,mask) in val_generator:\n",
        "        new_mask = adjust_mask(mask)\n",
        "        yield (img,new_mask)\n",
        "\n",
        "def test_generator_fn():  \n",
        "    for (img,mask) in test_generator:\n",
        "        new_mask=adjust_mask(mask)\n",
        "        yield (img,new_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCPp6sy9Gtsl"
      },
      "source": [
        "모델 실행 및 시각화\n",
        "---\n",
        "파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXR2eNZqG1U1"
      },
      "source": [
        "batch_sz = 4\n",
        "epochs = 10\n",
        "steps_per_epoch = 1000\n",
        "validation_steps = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z37sxPuOGsNV"
      },
      "source": [
        "n_train_samples = len(os.listdir(str(data_path) + '/Original_Train'))\n",
        "n_train_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziQAfuJUIcXU"
      },
      "source": [
        "steps_per_epoch=n_train_samples 해도 됨  \n",
        "train학습, valid평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx_YWOX2G7R1"
      },
      "source": [
        "model_checkpoint = ModelCheckpoint('unet_camvid.hdf5', monitor='val_loss',verbose=1, save_best_only=True)\n",
        "model.fit_generator(train_generator_fn(),\n",
        "                    validation_data=val_generator_fn(),\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    validation_steps=validation_steps,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_ALZO3GYJcM"
      },
      "source": [
        "scores=model.evaluate_generator(test_generator_fn(),steps=5)\n",
        "scores[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7nTzPhsHYkV"
      },
      "source": [
        "시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn2doq3-Qbco"
      },
      "source": [
        "# img (256,256,3)\n",
        "# gt_mask: gt_mode=sparse--> (256,256) or ohe --> (256,256,32)\n",
        "def visualize_seg(img, gt_mask, shape='normal', gt_mode='sparse'):\n",
        "    plt.figure(1)\n",
        "\n",
        "      # Img\n",
        "    plt.subplot(311)\n",
        "    plt.imshow(img)\n",
        "\n",
        "      # Predict\n",
        "    pred_mask = model.predict(np.expand_dims(img, 0))\n",
        "    pred_mask = np.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = pred_mask[0]\n",
        "    if shape=='flat':\n",
        "        pred_mask = np.reshape(pred_mask, (256,256)) # Reshape only if you use the flat model. O.w. you dont need\n",
        "\n",
        "    rgb_mask = np.apply_along_axis(map_class_to_rgb, -1, np.expand_dims(pred_mask, -1))\n",
        "\n",
        "    # Prediction\n",
        "    plt.subplot(312)\n",
        "    plt.imshow(rgb_mask)\n",
        "\n",
        "    # GT mask\n",
        "    if gt_mode == 'ohe':\n",
        "        gt_img_ohe = np.argmax(gt_mask, axis=-1)\n",
        "        gt_mask = np.apply_along_axis(map_class_to_rgb, -1, np.expand_dims(gt_img_ohe, -1))              \n",
        "\n",
        "    plt.subplot(313)\n",
        "    plt.imshow(gt_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzy_48dqHans"
      },
      "source": [
        "img = next(test_image_generator)[0]\n",
        "gt_img = next(test_mask_generator)[0]\n",
        "visualize_seg(img, gt_img, gt_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}