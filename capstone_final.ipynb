{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5xcA5AuDP7J"
   },
   "source": [
    "데이터 불러오기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPO3hh80TmbG"
   },
   "source": [
    "colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVTUkDzHSWaf"
   },
   "outputs": [],
   "source": [
    "data_path='./data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "image_file_list=os.listdir(data_path+'images')\n",
    "mask_file_list=os.listdir(data_path+'masks')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(image_file_list,mask_file_list,test_size=0.2,shuffle=False,random_state=1004)\n",
    "X_train,X_val,Y_train,Y_val=train_test_split(X_train,Y_train,test_size=0.2,shuffle=False,random_state=1004)\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "createFolder(data_path+'Original_Train')\n",
    "createFolder(data_path+'Original_Test')\n",
    "createFolder(data_path+'Original_val')\n",
    "createFolder(data_path+'Mask_Train')\n",
    "createFolder(data_path+'Mask_Test')\n",
    "createFolder(data_path+'Mask_val')\n",
    "\n",
    "import shutil\n",
    "src=data_path+'images/'\n",
    "dir=data_path+'Original_Train/'\n",
    "for i in range(len(X_train)):\n",
    "    shutil.copy(src+X_train[i],dir+X_train[i])\n",
    "\n",
    "src=data_path+'masks/'\n",
    "dir=data_path+'Mask_Train/'\n",
    "for i in range(len(Y_train)):\n",
    "    shutil.copy(src+Y_train[i],dir+Y_train[i])\n",
    "\n",
    "src=data_path+'images/'\n",
    "dir='./data/Original_Test/'\n",
    "for i in range(len(X_test)):\n",
    "    shutil.copy(src+X_test[i],dir+X_test[i])\n",
    "\n",
    "src=data_path+'masks/'\n",
    "dir=data_path+'Mask_Test/'\n",
    "for i in range(len(Y_test)):\n",
    "    shutil.copy(src+Y_test[i],dir+Y_test[i])\n",
    "    \n",
    "src=data_path+'images/'\n",
    "dir=data_path+'Original_val/'\n",
    "for i in range(len(X_val)):\n",
    "    shutil.copy(src+X_val[i],dir+X_val[i])\n",
    "    \n",
    "src=data_path+'masks/'\n",
    "dir=data_path+'Mask_val/'\n",
    "for i in range(len(Y_val)):\n",
    "    shutil.copy(src+Y_val[i],dir+Y_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IKUPANxDM2D"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "classes = pd.read_csv(data_path+'class_dict.csv', index_col =0)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41bj3Q4uDaat"
   },
   "outputs": [],
   "source": [
    "n_classes = len(classes)\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0nplon_TZTn"
   },
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AgyCQFyGNDs"
   },
   "outputs": [],
   "source": [
    "# Data generator\n",
    "#https://keras.io/preprocessing/image/\n",
    "# Data generator\n",
    "#batch_sz = 4\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# we create two instances with the same arguments\n",
    "\n",
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest',\n",
    "                    rescale=1./255)\n",
    "\n",
    "mask_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen  = ImageDataGenerator(**mask_gen_args) \n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "#image_datagen.fit(images, augment=True, seed=seed)\n",
    "#mask_datagen.fit(masks, augment=True, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMgQVUf4SWxn"
   },
   "source": [
    "data_path  6개 만들어야할 것 같은데..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iBQLCkPTv7w"
   },
   "source": [
    "generator 단위로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrcZpDb5Lf9r"
   },
   "outputs": [],
   "source": [
    "###train\n",
    "image_generator = image_datagenflow_from_directory.(\n",
    "    data_path,\n",
    "    class_mode=None,\n",
    "    classes=['Original_Train'],\n",
    "    seed=seed,\n",
    "    batch_size=batch_sz,\n",
    "    target_size=(256,256))\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    classes=['Mask_Train'],\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_sz,\n",
    "    target_size=(256,256))\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "###validation\n",
    "val_image_generator = image_datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    class_mode=None,\n",
    "    classes=['Original_val'],\n",
    "    seed=seed,\n",
    "    batch_size=batch_sz,\n",
    "    target_size=(256,256))\n",
    "\n",
    "val_mask_generator = mask_datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    classes=['Mask_val'],\n",
    "    class_mode=None,\n",
    "    seed=seed,\n",
    "    batch_size=batch_sz,\n",
    "    color_mode='rgb',\n",
    "    target_size=(256,256))\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "val_generator = zip(val_image_generator, val_mask_generator)\n",
    "\n",
    "###test\n",
    "test_image_generator=image_datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    class_mode=None,\n",
    "    classes=['Original_Test'],\n",
    "    seed=seed,\n",
    "    batch_size=batch_sz,\n",
    "    color_mode='rgb',\n",
    "    target_size=(256,256))\n",
    "\n",
    "test_mask_generator=image_datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    class_mode=None,\n",
    "    classes=['Mask_Test'],\n",
    "    seed=seed,\n",
    "    batch_size=batch_sz,\n",
    "    color_mode='rgb',\n",
    "    target_size=(256,256))\n",
    "\n",
    "test_generator=zip(test_image_generator,test_mask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzoJTBT4D44W"
   },
   "source": [
    "UNET 모델 정의\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETS8ICJAD6xn"
   },
   "outputs": [],
   "source": [
    "#Unet은 2015년에 출시한  Biomedical Image segmentation을 위한 convolutional network로 출시됨\n",
    "#End-to-End 로 Segmentation하는 심플하고 효과적인 방법\n",
    "#U-Net은 Fully Convolution Network(FCN)를 기반으로 하여 구축하였으며, 적은 데이터를 가지고도 더욱 정확한 Segmentaion을 내기 위해 FCN 구조를 수정\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "\n",
    "def unet(n_classes, pretrained_weights = None,input_size = (256,256,3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv10 = Conv2D(n_classes, (1,1), activation = 'softmax')(conv9)\n",
    "    conv10 = Conv2D(n_classes, (1,1), padding='same')(conv9)\n",
    "    \n",
    "\n",
    "    output_layer = conv10\n",
    "    output_layer = Activation('softmax')(output_layer)\n",
    "     \n",
    "\n",
    "    model = Model( inputs,output_layer)\n",
    "    \n",
    "    #케라스의 MeanIOU를 평가지표로 사용\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.MeanIoU(num_classes=32)])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4YtljOjD9e-"
   },
   "outputs": [],
   "source": [
    "model = unet(n_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJYO5oh3GJ19"
   },
   "source": [
    "Data generator 정의\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_Nj_aoHDpnF"
   },
   "outputs": [],
   "source": [
    "def adjust_mask(mask, flat=False):\n",
    "    \n",
    "    semantic_map = []\n",
    "    for colour in list(cls2rgb.values()):        \n",
    "        equality = np.equal(mask, colour)# 256x256x3 with True or False\n",
    "        class_map = np.all(equality, axis = -1)# 256x256 If all True, then True, else False\n",
    "        semantic_map.append(class_map)# List of 256x256 arrays, map of True for a given found color at the pixel, and False otherwise.\n",
    "    semantic_map = np.stack(semantic_map, axis=-1)# 256x256x32 True only at the found color, and all False otherwise.\n",
    "    if flat:\n",
    "        semantic_map = np.reshape(semantic_map, (-1,256*256))\n",
    "\n",
    "    return np.float32(semantic_map)# convert to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyyubBaCDxDm"
   },
   "outputs": [],
   "source": [
    "#new_mask = adjust_mask(mask)\n",
    "#new_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUUuJV6oS4Su"
   },
   "outputs": [],
   "source": [
    "def train_generator_fn():\n",
    "    for (img,mask) in train_generator:\n",
    "        new_mask = adjust_mask(mask)\n",
    "        yield (img,new_mask)\n",
    "\n",
    "def val_generator_fn():\n",
    "    for (img,mask) in val_generator:\n",
    "        new_mask = adjust_mask(mask)\n",
    "        yield (img,new_mask)\n",
    "\n",
    "def test_generator_fn():  \n",
    "    for (img,mask) in test_generator:\n",
    "        new_mask=adjust_mask(mask)\n",
    "        yield (img,new_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCPp6sy9Gtsl"
   },
   "source": [
    "모델 실행 및 시각화\n",
    "---\n",
    "파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXR2eNZqG1U1"
   },
   "outputs": [],
   "source": [
    "batch_sz = 4\n",
    "epochs = 10\n",
    "steps_per_epoch = 1000\n",
    "validation_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z37sxPuOGsNV"
   },
   "outputs": [],
   "source": [
    "n_train_samples = len(os.listdir(str(data_path) + '/Original_Train'))\n",
    "n_train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziQAfuJUIcXU"
   },
   "source": [
    "steps_per_epoch=n_train_samples 해도 됨  \n",
    "train학습, valid평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zx_YWOX2G7R1"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('unet_camvid.hdf5', monitor='val_loss',verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator_fn(),\n",
    "                    validation_data=val_generator_fn(),\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_steps=validation_steps,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_ALZO3GYJcM"
   },
   "outputs": [],
   "source": [
    "scores=model.evaluate_generator(test_generator_fn(),steps=5)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7nTzPhsHYkV"
   },
   "source": [
    "시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jn2doq3-Qbco"
   },
   "outputs": [],
   "source": [
    "# img (256,256,3)\n",
    "# gt_mask: gt_mode=sparse--> (256,256) or ohe --> (256,256,32)\n",
    "def test_visualize_seg(img, gt_mask, shape='normal'):\n",
    "    plt.figure(1)\n",
    "\n",
    "      # Img\n",
    "    plt.subplot(311)\n",
    "    plt.imshow(img)\n",
    "\n",
    "      # Predict\n",
    "    pred_mask = model.predict(np.expand_dims(img, 0))\n",
    "    pred_mask = np.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[0]\n",
    "    if shape=='flat':\n",
    "        pred_mask = np.reshape(pred_mask, (256,256)) # Reshape only if you use the flat model. O.w. you dont need\n",
    "\n",
    "    rgb_mask = np.apply_along_axis(map_class_to_rgb, -1, np.expand_dims(pred_mask, -1))\n",
    "\n",
    "    # Prediction\n",
    "    plt.subplot(312)\n",
    "    plt.imshow(rgb_mask)\n",
    "\n",
    "    plt.subplot(313)\n",
    "    plt.imshow((gt_mask).astype(np.float64))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzy_48dqHans"
   },
   "outputs": [],
   "source": [
    "img = next(test_image_generator)[0]\n",
    "gt_img = next(test_mask_generator)[0]\n",
    "test_visualize_seg(img, gt_img)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "capstone_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
